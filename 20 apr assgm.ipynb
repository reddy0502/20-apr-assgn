{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73f4cb1e-ac73-4cf9-9777-d19bccb3efc0",
   "metadata": {},
   "source": [
    "1ans:\n",
    "\n",
    "\n",
    "KNN stands for k-Nearest Neighbors, which is a simple and effective machine learning algorithm used for classification and regression tasks. It is a type of instance-based learning where the algorithm uses the distance between the features of the training data and the features of the new data to predict the target variable.\n",
    "\n",
    "The value of k is a hyperparameter that can be chosen by the user. Typically, a larger value of k results in a smoother decision boundary and less overfitting, while a smaller value of k can capture more complex decision boundaries.\n",
    "\n",
    "2ans:\n",
    "\n",
    " Here are some common methods to choose the value of K:\n",
    "\n",
    "Domain knowledge: If you have prior knowledge about the problem domain, you can use that to choose an appropriate value of K. For example, if you know that the decision boundary between classes is smooth, you can choose a larger value of K to obtain a smoother boundary.\n",
    "\n",
    "Elbow method: The elbow method is a graphical approach to choose the value of K. It involves plotting the accuracy of the model against different values of K and selecting the K value at the \"elbow\" of the curve, where the accuracy starts to plateau.\n",
    "\n",
    "Cross-validation: Cross-validation is a method to evaluate the performance of the model on a limited dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b24e178-15de-43a2-8752-2049f395cc3f",
   "metadata": {},
   "source": [
    "3ans:\n",
    "\n",
    "KNN classifier is a type of classification algorithm that predicts the class of a new data point based on the classes of its k-nearest neighbors. The target variable in a classification problem is categorical or discrete, meaning that it takes on a limited number of possible values or classes. For example, in a binary classification problem, the target variable can take on two values: 0 or 1.\n",
    "\n",
    "KNN regressor, on the other hand, is a type of regression algorithm that predicts the value of a continuous target variable for a new data point based on the values of its k-nearest neighbors. The target variable in a regression problem is continuous, meaning that it can take on any value within a range of values. For example, in a housing price prediction problem, the target variable is the price of the house, which can take on any positive real value.\n",
    "\n",
    "\n",
    "4ans:\n",
    "\n",
    " Here are some commonly used performance metrics for KNN:\n",
    "\n",
    "Classification accuracy: It measures the percentage of correctly classified instances. It is calculated as the ratio of the number of correct predictions to the total number of predictions.\n",
    "\n",
    "Confusion matrix: It is a table that summarizes the classification results. It shows the number of true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "Precision, recall, and F1-score: These are the measures of the quality of the classification model. Precision is the ratio of true positives to the total predicted positives, recall is the ratio of true positives to the total actual positives, and F1-score is the harmonic mean of precision and recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb28ad-bffb-4a71-943a-ad802b7fc254",
   "metadata": {},
   "source": [
    "5ans:\n",
    "\n",
    "The curse of dimensionality in KNN refers to the problem that arises when dealing with high-dimensional data, where the number of features or variables is much larger than the number of samples. In such cases, the KNN algorithm may become computationally expensive and may suffer from poor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd1066-c7d1-484f-87f6-ae4833721c92",
   "metadata": {},
   "source": [
    "6ans:\n",
    "\n",
    " Here are some common methods for handling missing values in KNN:\n",
    "\n",
    "Deletion: One way to handle missing values is to simply remove the instances with missing values. This approach may result in loss of information and reduced accuracy.\n",
    "\n",
    "Imputation: Another way is to replace the missing values with a reasonable estimate. Some common methods for imputing missing values are mean imputation, median imputation, and mode imputation. These methods replace the missing values with the mean, median, or mode of the feature values in the training set.\n",
    "\n",
    "KNN imputation: In this method, missing values are replaced by the mean or median value of the k nearest neighbors in the training set. This approach can be more effective than simple imputation methods as it takes into account the relationship between features.\n",
    "\n",
    "7ans:\n",
    "\n",
    " KNN classifier is better suited for classification problems where the number of classes is small and the decision boundary is well-defined, while KNN regressor is better suited for regression problems where the relationship between the features and the target variable is continuous and non-linear. However, the choice between KNN classifier and KNN regressor ultimately depends on the nature of the problem and the available data.\n",
    " \n",
    " 8ans:\n",
    " \n",
    " Strengths of KNN algorithm:\n",
    "\n",
    "Non-parametric: KNN is a non-parametric algorithm, which means that it does not make any assumptions about the underlying distribution of the data.\n",
    "\n",
    "Simple and easy to implement: KNN is a simple algorithm that is easy to implement and understand, making it a good choice for beginners.\n",
    "\n",
    "No training required: KNN does not require any training data, which means that it can be used for online learning or for problems where data is generated in real-time.\n",
    "\n",
    "Weaknesses of KNN algorithm:\n",
    "\n",
    "Computationally expensive: KNN can be computationally expensive, especially when dealing with large datasets or high-dimensional data.\n",
    "\n",
    "Sensitive to feature scaling: KNN is sensitive to the scale of the features, which means that it is important to scale the features before applying KNN to the data.\n",
    "\n",
    "Requires large memory: KNN requires a large amount of memory to store the entire dataset, which can be a problem for large datasets.\n",
    "\n",
    "To address these weaknesses, there are several techniques that can be applied, such as:\n",
    "\n",
    "Dimensionality reduction techniques: Dimensionality reduction techniques such as PCA or t-SNE can be used to reduce the number of features, which can help to reduce the computational complexity of KNN.\n",
    "\n",
    "Feature scaling: Feature scaling techniques such as normalization or standardization can be applied to scale the features and improve the performance of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed35de-0472-4dc4-bccf-92b8580cc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
